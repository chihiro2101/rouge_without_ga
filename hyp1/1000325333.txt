a naïve algorithm of an expert system might check each rule against known facts in a knowledge base , firing that rule if necessary , then moving on to the next rule ( and looping back to the first rule when finished ) a rete-based expert system builds a network of nodes , where each node ( except the root ) corresponds to a pattern occurring in the left-hand-side ( the condition part ) of a rule when a fact or combination of facts causes all of the patterns for a given rule to be satisfied , a leaf node is reached and the corresponding rule is triggered rete was first used as the core engine of the ops5 production system language which was used to build early systems including r1 for digital equipment corporation rete has become the basis for many popular rule engines and expert system shells , including tibco business events , newgen omnirules , clips , jess , drools , ibm operational decision management , opsj , blaze advisor , biztalk rules engine , soar , clara and sparkling logic smarts '' rete algorithm demystified ! – part 1 '' by carole-ann matignon the rete algorithm is designed to sacrifice memory for increased speed in most cases , the speed increase over naïve implementations is several orders of magnitude ( because rete performance is theoretically independent of the number of rules in the system ) the rete algorithm provides a generalized logical description of an implementation of functionality responsible for matching data tuples ( '' facts '' ) against productions ( '' rules '' ) in a pattern-matching production system ( a category of rule engine ) a production consists of one or more conditions and a set of actions which may be undertaken for each complete set of facts that match the conditions this , in turn , allows production systems to avoid complete re-evaluation of all facts each time changes are made to the production system 's working memory the root node passes each wme on to its child nodes , and each wme may then be propagated through the network , possibly being stored in intermediate memories , until it arrives at a terminal node in this article , however , we will describe data propagation in terms of wme lists , rather than tokens , in recognition of different implementation options and the underlying purpose and use of tokens wme lists that reach the end of a branch of beta nodes represent a complete match for a single production , and are passed to terminal nodes when a join node is right-activated , it compares one or more attributes of the newly stored wme from its input alpha memory against given attributes of specific wmes in each wme list contained in the input beta memory logically , a beta node at the head of a branch of beta nodes is a special case because it takes no input from any beta memory higher in the network the order may be based on rule priority ( salience ) , rule order , the time at which facts contained in each instance were asserted to the working memory , the complexity of each production , or some other criteria conflict resolution is not defined as part of the rete algorithm , but is used alongside the algorithm the engine undertakes matching of the changed data which , in turn , may result in changes to the list of production instances on the agenda some engines support a model in which , instead of halting when the agenda is empty , the engine enters a wait state until new facts are asserted externally as for conflict resolution , the firing of activated production instances is not a feature of the rete algorithm a good indexing strategy is a major factor in deciding the overall performance of a production system , especially when executing rule sets that result in highly combinatorial pattern matching ( i.e for a more detailed and complete description of the rete algorithm , see chapter 2 of production matching for large learning systems by robert doorenbos ( see link below ) this increases the overhead of the rete , but may have advantages in situations where rules are dynamically added to or removed from the rete , making it easier to vary the topology of the discrimination network dynamically production matching for large learning systems from scs technical report collection , school of computer science , carnegie mellon university in this case , the discrimination network is replaced by a set of memories and an index each memory holds wmes that match a single conditional pattern , and the index is used to reference memories by their pattern when a wme enters the rete , the index is used to locate a set of memories whose conditional pattern matches the wme attributes , and the wme is then added directly to each of these memories instead , a beta node needs only to create a new token to hold a wme it wishes to join to the partial match list , and then link the new token to a parent token stored in the input beta memory in this case , the beta nodes typically pass lists of wmes through the beta network by copying existing wme lists from each received token into new tokens and then adding further wmes to the lists as a result of performing a join or some other action for example , when a match is found for one production , this may result in the assertion of new wmes which , in turn , match the conditions for another production if a subsequent change to working memory causes the first match to become invalid , it may be that this implies that the second match is also invalid justification refers to mechanisms commonly required in expert and decision systems in which , at its simplest , the system reports each of the inner decisions used to reach some final conclusion for example , an expert system might justify a conclusion that an animal is an elephant by reporting that it is large , grey , has big ears , a trunk and tusks for example , engines may provide specialised support within the rete network in order to apply pattern-matching rule processing to specific data types and sources such as programmatic objects , xml data or table ( database ) engines exhibit significant variation in the way they allow programmatic access to the engine and its working memory , and may extend the basic rete model to support forms of parallel and distributed processing several of these , however , apply only in very specific scenarios , and therefore often have little or no application in a general-purpose rules engine the rete algorithm is suited to scenarios where forward chaining and '' inferencing '' is used to calculate new facts from existing facts , or to filter and discard facts in order to arrive at some conclusion other approaches to performing rule evaluation , such as the use of decision trees , or the implementation of sequential engines , may be more appropriate for simple scenarios , and should be considered as possible alternatives to mention only a frequent bias and an unfair type of comparison : 1 ) the use of toy problems such as the manners and waltz examples ; such examples are useful to estimate specific properties of the implementation , but they may not reflect real performance on complex applications ; 2 ) the use of an old implementation ; for instance , the references in the following two sections ( rete ii and rete-nt ) compare some commercial products to totally outdated versions of clips and they claim that the commercial products may be orders of magnitude faster than clips ; this is forgetting that clips 6.30 ( with the introduction of hash tables as in rete ii ) is orders of magnitude faster than the version used for the comparisons ( clips 6.04 ) in the 1980s , charles forgy developed a successor to the rete algorithm named rete ii rete ii claims better performance for more complex problems ( even orders of magnitude benchmarking clips/r2 from production systems technologies ) , and is officially implemented in clips/r2 , a c/++ implementation and in opsj , a java implementation in 1998 rete ii can be characterized by two areas of improvement ; specific optimizations relating to the general performance of the rete network ( including the use of hashed memories in order to increase performance with larger sets of data ) , and the inclusion of a backward chaining algorithm tailored to run on top of the rete network rete ii is implemented in the commercial product advisor from fico , formerly called fair isaac jess ( at least versions 5.0 and later ) also adds a commercial backward chaining algorithm on top of the rete network , but it can not be said to fully implement rete ii , in part due to the fact that no full specification is publicly available in the early 2000s , the rete iii engine was developed by charles forgy in cooperation with fico engineers the rete iii algorithm , which is not rete-nt , is the fico trademark for rete ii and is implemented as part of the fico advisor engine in an infoworld benchmark , the algorithm was deemed 500 times faster than the original rete algorithm and 10 times faster than its predecessor , rete ii this algorithm is now licensed to sparkling logic , the company that forgy joined as investor and strategic advisor , as the inference engine of the smarts product . 
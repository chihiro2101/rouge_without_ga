these moves usually result in minimal alterations of the last state , in an attempt to progressively improve the solution through iteratively improving its parts ( such as the city connections in the traveling salesman problem ) simple heuristics like hill climbing , which move by finding better neighbour after better neighbour and stop when they have reached a solution which has no neighbours that are better solutions , can not guarantee to lead to any of the existing better solutions their outcome may easily be just a local optimum , while the actual best solution would be a global optimum that could be different metaheuristics use the neighbours of a solution as a way to explore the solution space , and although they prefer better neighbours , they also accept worse neighbours in order to avoid getting stuck in local optima ; they can find the global optimum if run for a long enough amount of time to investigate the behavior of simulated annealing on a particular problem , it can be useful to consider the transition probabilities that result from the various design choices made in the implementation of the algorithm for each edge ( s , s ' ) of the search graph , the transition probability is defined as the probability that the simulated annealing algorithm will move to state s ' when its current state is s this probability depends on the current temperature as specified by , on the order in which the candidate moves are generated by the function , and on the acceptance probability function however , this acceptance probability is often used for simulated annealing even when the function , which is analogous to the proposal distribution in metropolis–hastings , is not symmetric , or not probabilistic at all as a result , the transition probabilities of the simulated annealing algorithm do not correspond to the transitions of the analogous physical system , and the long-term distribution of states at a constant temperature t need not bear any resemblance to the thermodynamic equilibrium distribution over states of that physical system , at any temperature moscato and fontanari conclude from observing the analogous of the '' specific heat '' curve of the '' threshold updating '' annealing originating from their study that '' the stochasticity of the metropolis updating in the simulated annealing algorithm does not play a major role in the search of near-optimal minima '' instead , they proposed that '' the smoothening of the cost function landscape at high temperature and the gradual definition of the minima during the cooling process are the fundamental ingredients for the success of simulated annealing therefore , as a general rule , one should skew the generator towards candidate moves where the energy of the destination state s ' is likely to be similar to that of the current state this heuristic ( which is the main principle of the metropolis–hastings algorithm ) tends to exclude '' very good '' candidate moves as well as '' very bad '' ones ; however , the former are usually much less common than the latter , so the heuristic is generally quite effective in the traveling salesman problem above , for example , swapping two consecutive cities in a low-energy tour is expected to have a modest effect on its energy ( length ) ; whereas swapping two arbitrary cities is far more likely to increase its length than to decrease it thus , the consecutive-swap neighbour generator is expected to perform better than the arbitrary-swap one , even though the latter could provide a somewhat shorter path to the optimum ( with n-1 swaps , instead of n ( n-1 ) /2 ) such '' closed catchment basins '' of the energy function may trap the simulated annealing algorithm with high probability ( roughly proportional to the number of states in the basin ) and for a very long time ( roughly exponential on the energy difference between the surrounding states and the bottom of the basin ) in the traveling salesman problem , for instance , it is not hard to exhibit two tours a , b , with nearly equal lengths , such that ( 1 ) a is optimal , ( 2 ) every sequence of city-pair swaps that converts a to b goes through tours that are much longer than both , and ( 3 ) a can be transformed into b by flipping ( reversing the order of ) a set of consecutive cities lionsolver focuses on combining machine learning with optimization , by adding an internal feedback loop to self-tune the free parameters of an algorithm to the characteristics of the problem , of the instance , and of the local situation around the current solution 